# The Discourse is a Distributed Denial-of-Service Attack

![rw-book-cover](https://images.unsplash.com/photo-1602475063211-3d98d60e3b1f?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDF8fG5vaXNlfGVufDB8fHx8MTc2ODY5MjMzNHww&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=2000)

## Metadata
- Author: [[Joan Westenberg]]
- Full Title: The Discourse is a Distributed Denial-of-Service Attack
- Category: #articles
- Publication date: 2026-01-17
- Document Tags: [[criticism]] [[internet]] [[politics]] 
- URL: https://www.joanwestenberg.com/the-discourse-is-a-distributed-denial-of-service-attack/
- Summary: The Discourse is like a big online attack called a Distributed Denial-of-Service. It overwhelms websites with too much traffic. This makes the site slow or stop working.

# Notes

[[Joan Westenberg - The Discourse is a Distributed Denial-of-Service Attack]]

***

![The Discourse is a Distributed Denial-of-Service Attack](https://images.unsplash.com/photo-1602475063211-3d98d60e3b1f?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDF8fG5vaXNlfGVufDB8fHx8MTc2ODY5MjMzNHww&ixlib=rb-4.1.0&q=80&w=1140)
In September 2016, the security journalist Brian Krebs had his website knocked offline by a botnet called Mirai. Hundreds of thousands of compromised devices, mostly cheap webcams and DVRs manufactured with default passwords that nobody ever changed, all simultaneously requesting his homepage. No single request was malicious. Each packet was perfectly legitimate traffic. But the sheer volume of simultaneous demands overwhelmed his servers until they simply gave up. It collapsed under the weight of too many people wanting something from it at once.

We are all Brian Krebs now, and the botnet is the discourse itself.

A Distributed Denial-of-Service attack works by exhausting resources. It doesn't need to be clever. It just needs to be overwhelming. The target's defenses are simply overrun. The server can't distinguish between legitimate requests and attack traffic because, in a sense, all the traffic is legitimate. The attack succeeds when the system has spent so much energy processing requests that it can no longer serve its actual function.

You're trying to think carefully about a genuinely difficult problem. Maybe you want to understand the actual tradeoffs in housing policy, or AI, or figure out what you believe about consciousness // immigration // Fallout Season 2 // Iran. This takes time. It takes holding multiple ideas in your head simultaneously while following chains of reasoning and sitting with uncertainty long enough to let clarity...well, for lack of a better word, emerge.

William James, writing in 1890, called this "the effort of attention." He noted that sustaining it was one of the hardest things a mind could do. The effort of attention could only be maintained for a few seconds at a time before the mind wandered off to do something else. Sustained concentration was really a series of these efforts, renewed again and again, each time pulling the mind back to the object of focus.

Now imagine trying to do this while someone shouts a new outrage at you every four minutes.

### The Architecture of Exhaustion

The discourse operates on exactly this principle. Most of the topics that dominate our collective attention on any given day are genuinely important to... someone. And many of them are important to almost everyone. The problem is structural. The total volume of things-you-should-have-an-opinion-about has exceeded our cognitive bandwidth so thoroughly that having careful opinions about anything has become damned-near impossible. Your attention is a finite resource being strip-mined by an infinite army of takes.

"The discourse is bad" is itself a discourse-position, and I'm aware of the irony of adding another take to the pile of steaming shit. But my argument isn't that people should stop having opinions, or that controversies aren't worth discussing, or that we should all log off and touch grass (none of us will). My argument is that the current structure of public conversation has the same effect on human cognition that a botnet has on a web server. It's simply exhausting you. And an exhausted mind defaults to heuristics and tribal allegiances, aka whatever position allows it to conserve the most cognitive energy.

T.S. Eliot wrote about being "distracted from distraction by distraction," and he was describing the London of 1935. I wonder what he'd make of our current situation. The distractions have learned to replicate themselves and fight each other for dominance of your prefrontal cortex...

The old media ecosystem had gatekeepers, and those gatekeepers were often stupid or corrupt, but at least the stupidity and corruption were bounded. There were only so many column inches in the New York Times, only so many minutes of evening news. A finite supply of attention-worthy items existed, and someone had to decide which ones made the cut. That selection process was biased and imperfect, but it performed an important function: it told you, implicitly, that you didn't have to have an opinion about everything. Most things that happened in the world weren't important enough to make it into your awareness at all. Local political disputes in New South Wales? Nobody in Washington DC gave a shit, and vice-versa. This was as close to optimal as we've ever got.

But the gatekeeping function has now been distributed across millions of individual users, each of whom can boost any piece of content into viral prominence if it happens to resonate with the right combination of tribal anxieties and engagement incentives. The feed is infinite, and every slot in the feed is optimized to make you feel something strongly enough that you'll engage with it. Outrage works, and so does fear. Disgust works, and righteousness really fucking works. Nuance and careful reasoning don't work at all, because by the time you've finished a thought that begins with "Well, it's complicated..." someone else has already posted a much simpler take that makes people feel validated, and the algorithm has moved on.

In a technical DDoS attack, the goal isn't to steal data or corrupt systems. The goal is to exhaust resources. To prevent the target from doing anything useful by forcing it to spend all its energy processing garbage. The attack succeeds when the server is so busy responding to fake requests that it can't handle real ones. Crucially, the attack doesn't need to compromise the server's judgment or trick it into making bad decisions. It just needs to make sure the server never has time to make good ones.

What would it look like if this were happening to the collective human capacity for sustained thought?

It might look like a society that can generate infinite commentary but rarely produces wisdom. It might look like millions of people who can instantly articulate a position on any topic but who struggle to change their minds when confronted with new evidence. It might look like a discourse that has strong opinions about everything and deep understanding of almost nothing. It might look like a world where the most engaged and informed citizens are, paradoxically, the least capable of careful reasoning, because they've spent so much cognitive energy responding to controversies that they have none left for contemplation.

I think that's more or less where we've wound up.

### From Passive to Participatory

Neil Postman argued in 1985 that television was creating a culture where everything became entertainment, including serious matters that deserved more somber treatment. His book *Amusing Ourselves to Death* made the case that we'd been so worried about Orwell's dystopia, the boot stamping on a human face forever, that we'd missed Huxley's sneaking up on us from the other direction. We would be destroyed by what we loved, not by what we feared. The problem wasn't that Big Brother was watching us; it was that we couldn't stop watching Big Brother.

But television, at least, was passive. You sat there and it washed over you. You could zone out, let your mind wander, process what you'd seen during the commercial breaks. The discourse is participatory. It demands engagement. Every controversy comes with an implied social pressure to have a take, to signal your tribal allegiance, to demonstrate that you understand what's happening and have correctly identified the good guys and the bad guys. Silence is interpreted as complicity, or at least as suspicious. "I haven't thought about this enough to have an opinion" is not an acceptable response when everyone else is already fighting.

And because the controversies are endless, because there's always another one queueing up behind the current while you're still processing the last three, the effect is a constant low-grade cognitive emergency. Your brain never gets to switch out of reactive mode and into reflective mode. You're always responding to the latest thing, putting out fires, engaging with the controversy of the day. Daniel Kahneman's distinction between System 1 (fast, automatic, intuitive) and System 2 (slow, deliberate, analytical) thinking is useful here: the discourse is structured in such a way that System 2 never gets its turn. By the time you've marshaled the cognitive resources to think carefully about something, the conversation has moved on and you're already three outrages behind.

In *Middlemarch* George Eliot writes about how we'd go mad if we could hear the "roar which lies on the other side of silence," the constant suffering of all the people and creatures in the world happening simultaneously. She meant it as an argument for why we shouldn't feel guilty about our bounded sympathies, and why it was okay that we couldn't care about everything at once. But we've built a machine that lets us hear that roar, or at least a curated selection of it, delivered directly to our phones at all hours. And while we haven't gone mad exactly, we've developed something like a collective attention disorder.

Someone usually objects at this point that I'm showing my privilege.

The things people argue about on Twitter aren't frivolous! Violence is real! Climate change is happening! Democratic institutions are under threat! ICE is out of control! The President // insert popular figure here is a Nazi! Sports are under attack! Immigration is a crisis! The economy is going to shit! And how dare I suggest that people should care less about these things?

The knee-jerk objections misunderstand my point completely. I'm not saying the topics are unimportant. I'm saying the structure of the discourse prevents us from thinking well about even the most important topics. If anything, the importance of the issues makes the DDoS attack worse, because people have strong emotional investment in their positions, which generates more engagement, which generates more outrage cycles, which leaves less time for anyone to actually sit down and think through what we should do about any of it.

What's the right carbon price? How should the burden of decarbonization be distributed between developed and developing countries? What role should nuclear power play? How do we balance climate concerns against other development goals?

These are hard questions.

What does the discourse give us instead? Endless fights about whether climate change is real (it is), whether specific weather events prove or disprove it (they mostly don't, it's complicated), whether teenagers skipping school to protest is admirable or annoying, whether it's okay to fly on airplanes if you care about climate, whether this or that celebrity is a hypocrite for having a large house, and so on, and so on, forever. The discourse takes the most important problem of our time and converts it into an infinite series of tribal skirmishes, each of which generates heat and engagement while bringing us no closer to answering any of the actual hard questions.

The discourse doesn't help us think about things. It helps us perform thinking about things, which is a different activity entirely.

There is a critical distinction between having a position and understanding a subject. Having a position involves knowing which side you're on and being able to articulate a view. Understanding a subject involves knowing why the question is hard, what the best arguments on various sides are, where the genuine uncertainties lie, and what evidence would change your mind. You can have a position on something without understanding it, and you can understand something without having a confident position on it.

The discourse is great at generating positions. It's terrible at generating understanding. In fact, it actively undermines understanding. Understanding involves sitting with difficulty and ambiguity, while the discourse rewards confidence and clarity. Understanding involves admitting what you don't know, while the discourse punishes uncertainty as weakness. Understanding involves engaging with the best version of opposing views, while the discourse treats opposition as either stupidity or malice.

There's a reason Socrates went around asking questions rather than giving speeches. The Socratic method works by forcing people to confront the gaps in their own reasoning, to follow their beliefs to their logical conclusions and notice when those conclusions are absurd or contradictory. It's slow and frustrating, usually ending with everyone realizing they understand less than they thought they did.

Can you imagine a Socratic dialogue with 50,000 likes?

### The Confidence Doom Spiral

The philosopher Bertrand Russell remarked that the fundamental cause of trouble in the world is that the stupid are cocksure while the intelligent are full of doubt. I think the discourse has broken this relationship. It's not that intelligent people have become stupid. It's that the incentive structure of public conversation rewards cocksureness regardless of actual intelligence. Smart people who admit uncertainty get steamrolled by confident idiots, so they learn to sound more confident than they feel, which degrades the quality of public discourse, which makes everyone stupider, which makes cocksureness even more adaptive. The result is a doom spiral.

There's a cybersecurity concept called defense in depth: the idea that you should have multiple layers of security, so that if one fails, others will catch the problem. Good epistemic institutions worked the same way. You had journalists who checked facts, editors who pushed back on weak arguments, academic peer review that caught errors, and a reading public that had time to actually read long articles and form considered opinions. Each layer could fail, and often did, but the failures were usually independent of each other, so the system as a whole was reasonably robust.

The discourse has collapsed all these layers into a single surface, a real-time arena where everyone reacts to everything simultaneously. There's no fact-checking layer between the event and the take, and there's no editorial layer between the take and the audience. Everything happens at once, in public, under the pressure of engagement metrics that reward speed and emotional intensity. The defense in depth is gone. We've replaced a layered epistemic system with a single point of failure, and then we've aimed a botnet at it.

### An Ecology of Virality

Yes, social media is a major factor in all of this, and yes, the incentive structures of platforms are part of the problem. But I want to resist the framing that makes this purely a technology story. The discourse predates social media. The dynamics I'm describing were visible in the blogosphere of the mid-2000s, in the talk radio ecosystem of the 1990s, in the cable news wars that started with CNN and accelerated with Fox. Social media has amplified and accelerated these dynamics, but it didn't create them. The underlying cause is something deeper and it's about how humans interact when controversy becomes abundant and attention becomes scarce.

When two species compete for the same resource, eventually one drives the other to extinction. The evolutionary pressure favors whichever species is better at acquiring the contested resource. When many ideas compete for limited attention, the ideas that are best at capturing attention win, and those that aren't good at it die out. This creates selection pressure toward attention-grabbing content, which tends to be extreme, emotional, simple, tribal, and visceral. The ideas that survive aren't the most true or useful. They're the most viral.

And virality, it turns out, has almost nothing to do with truth or usefulness.

False stories are 70% more likely to be retweeted than true ones, and they reach their first 1,500 retweets six times faster. When researchers controlled for the influence of bots they found that humans, not automated accounts, were primarily responsible for spreading false information.

We do this shit to ourselves. We are our own botnet.

Why would humans preferentially spread false information?

False information is more novel and surprising, so it generates more engagement. False information is often designed (or evolves through memetic selection) to be emotionally compelling in ways that true information isn't. The truth is boring, complicated, inconvenient for everyone's narrative, and resistant to simplification. Lies can be exciting and simple, perfectly calibrated to make your side look good and the other side look bad.

False information spreads faster because it's easier to process. It fits neatly into existing mental categories. It confirms what we already believe. It doesn't force us to update our models of the world or sit with uncomfortable ambiguity. True information violates our expectations and takes cognitive work to integrate. When attention is scarce and cognitive bandwidth is being DDoS'd constantly, we don't have the resources to do that work. So we default to whatever is easiest, which is usually wrong.

### The Impossible Position of Expertise

One of the main functions of experts in a healthy epistemic ecosystem is to compress information. A good scientist knows a lot of facts about X, but more importantly they know which facts matter, how different pieces of evidence fit together, and where the genuine debates are versus where there's solid consensus. When you ask an expert a question, you're essentially borrowing their cognitive labor. They've already done the hard work of understanding the subject, so you don't have to.

But the discourse hates expertise. Or rather, it puts experts in an impossible position. To engage with the discourse, an expert has to compress their nuanced understanding into takes that can compete with the confident nonsense being spouted by random accounts with anime avatars. This compression loses most of what makes expertise valuable in the first place. The expert ends up sounding just as confident and simplistic as everyone else, because that's the only way to be heard. Meanwhile, the expert's nuance and uncertainty get interpreted as weakness or evasion. Why won't they just give us a straight answer? Probably because they're captured by some special interest, or because they're part of the establishment cover-up, or because they're just not very good at their job.

This creates a vicious cycle. Experts withdraw from public discourse because it's frustrating and unrewarding, which leaves the field to confident non-experts and degrades the quality of public understanding, which makes it even harder for experts to engage productively when they do try to participate. The result is an environment that's actively hostile to expertise while claiming to value science and evidence.

### Consciousness as Disease

In Dostoevsky's *Notes from Underground* the narrator talks about how consciousness is a disease. The more aware you are of everything, the more paralyzed you become. You can see all sides of every question and understand all the complications, and as a result, you can't actually do anything. Meanwhile, the stupid people of action, the "men of iron," barrel forward confidently, untroubled by doubt, and end up running the world.

The people who are most capable of nuanced understanding are the same people who are most likely to be paralyzed by it. They see all the complications and worry about unintended consequences. And while they're doing all that, the confident idiots have already won the argument by sheer force of certainty. The discourse selects for confidence, not competence.

Repeated behaviors become habits and habits become character. If you spend years in an environment that rewards quick reactions, that punishes nuance and rewards certainty, that treats every disagreement as a battle and every interlocutor as an enemy, you will become the sort of person who thinks quickly rather than carefully, who speaks confidently rather than honestly. The discourse doesn't just waste your time while you're in it. It permanently rewires you.

I've watched this happen to people I know. Intelligent, curious, open-minded people who got deeply involved in online discourse and gradually, imperceptibly, became incapable of the exploratory thinking they used to do. Their opinions calcified. Their curiosity curdled into suspicion. They stopped asking questions and started scoring points. They'd defend positions they'd never actually thought through because those positions had become part of their identity, markers of tribal belonging that couldn't be questioned without threatening their sense of self.

The discourse doesn't merely DDoS your attention. Over time, it DDoS's your character.

### The Halting Problem of Public Conversation

Let me try another analogy. In computer science, there's a concept called the halting problem: the impossibility of writing a program that can determine, for any arbitrary program and input, whether that program will eventually halt or run forever. Alan Turing proved in 1936 that no such algorithm can exist. The halting problem is undecidable.

The discourse has something like a collective halting problem. Every controversy generates commentary, and that commentary generates meta-commentary. Where does it stop? When is a topic resolved? When can we move on? There's no algorithm for this. The discourse doesn't halt. It just continues until something newer and shinier captures our attention, at which point the old controversy doesn't get resolved so much as abandoned. The underlying issues remain, waiting to resurface the next time something triggers them.

This is why the same arguments keep happening over and over. We never actually resolve anything. We just get exhausted and move on to the next thing, and when the topic comes back around, we're exactly where we started, having learned nothing in the interim. The discourse isn't a process that converges on truth over time. It's a holding pattern. We circle endlessly without ever landing.

The discourse is a coordination failure. Even if I personally stop engaging with the outrage cycle, the cycle continues without me, and I become less able to participate in public life as a result. The social pressure to have positions on things doesn't disappear just because I've decided I'd rather understand things instead. My friends still want to know what I think about the latest controversy. My colleagues, the folks in the writers chats and Discord servers etc still expect me to be current on what's happening. Opting out of the discourse is possible, but it has social costs, and it doesn't do anything to change the dynamics for everyone else.

The incentive structures are too strong, the coordination problems too hard, the technological affordances too stacked in favor of engagement over understanding. We're stuck with a system that turns every important question into an attention competition and every attention competition into a tribal battle and every tribal battle into a cognitive emergency. The servers are overloaded. The requests keep coming.

### The Loss of Aura

Orwell feared those who would ban books. Huxley feared that there would be no reason to ban a book, for there would be no one who wanted to read one. But the discourse suggests a third possibility: a world with infinite books, infinite takes, infinite content of every kind, delivered at such volume and velocity that reading any of it becomes impossible.

Walter Benjamin wrote in 1936 about how mechanical reproduction was changing our relationship to art. A painting in a museum had an "aura," a sense of presence and authenticity that came from being in the presence of the original. Mass reproduction destroyed that aura. Benjamin thought this was mostly a good thing, democratizing access to culture. But he worried about what would be lost when nothing felt special anymore, when everything was just a copy of a copy with no original left to anchor it.

Every thought, every argument, every position now exists in thousands of variations, all slightly different, all competing for attention, all copying and remixing each other. There's no original anymore, no authoritative version, no canonical text. Just an endless proliferation of takes, each one slightly tweaked for maximum engagement. The aura is gone. Every idea feels like a retweet of something you've already seen, because it probably is.

The world doesn't pause while we figure out how to have functional public discourse again. Things happen, and they happen in the direction that the confident and powerful push them, because the rest of us are too busy processing the latest outrage to mount a coherent response.

Every attempt to discuss the problem becomes another piece of content, another take, another entry in the engagement competition that makes the problem worse. I'm aware that this essay is doing exactly that. I'm aware that you, reading this, are spending cognitive resources on yet another analysis of the discourse when you could be spending those resources on something more important. I'm sorry. I'm not sure what else to do.

What I do know is that the feeling of being overwhelmed, of never being able to keep up, of having strong opinions about everything and confident understanding of nothing, is not a personal failing. It's a predictable response to an impossible situation. Your brain is being DDoS'd, and the fact that you're struggling to think clearly under that onslaught is evidence that your brain is working normally. The servers aren't broken. They're overloaded. And until we figure out how to reduce the load or increase the bandwidth, the best any of us can do is recognize what's happening and try, when possible, to step away from the flood long enough to do some actual thinking.

Find some topic you care about. Just one. Resist the temptation to have takes on everything else. Let the discourse rage without you while you spend weeks or months actually understanding something. Read books about it, not takes. Talk to experts, not pundits. Follow the evidence where it leads, even when it's uncomfortable. Change your mind when you find you were wrong. And when you finally have something to say, something you've actually earned through careful thought rather than absorbed from the tribal zeitgeist, say it clearly and then step back.

This won't fix the collective problem. But it will fix something in you. And if enough people do it, we'll discover that we can still think after all, that the capacity for sustained attention hasn't been destroyed, just buried under a mountain of requests we never should have tried to answer. We'll learn to tell the difference between having a take and understanding something, and we'll start to value the latter again. Somewhere underneath all that noise, the servers are still there, waiting for the traffic to clear so they can finally do their job.
