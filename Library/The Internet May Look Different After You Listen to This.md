---
Author: Emily Keegin
Full Title: The Internet May Look Different After You Listen to This
Category:
URL: https://getmatter.com/article/112058776/
Publication: The New York Times
---

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png)

## Highlights
- Oh, no. There's no way that we can become more savvy. I think one of the things that people, certainly in my world, who think about the digital space and the social world are pretty much in agreement about is that this is not a problem that developing the right skill set is going to solve.
    - Note: Interesting perspective, although I don’t know if I agree. Let me try it on. General populations don’t get savvy. “Savvy” means you’re particularly adept at something, relative to a more unskilled person. It is a comparative descriptor. If we believe the discerning AI generated content from not is a task that requires savviness, then we are saying the vast majority of people cannot do it. 
      Where I struggle with this line of reasoning (and who knows if this is actually what the reporter is saying) is that general populations had of course developed skills that previously were nonexistent. People learned to type. People learned to use cell phone cameras. We weren’t born with those skills. But maybe that’s not *savviness* — a person might know how to use a cell phone camera but they may not be savvy at it. 
      So is this person’s argument that the skill required is so technical that it will not become generalized?
- They're all real footage, but you can see something very different depending on the angle from which it's filmed. And if we can't agree on how we're reading real images, how can we agree in a world where we can't even know if the Images are real.
    - Note: Destabilized society
- I would be even more pointed and say there is no economic incentive for these platforms to do a better job of making consumers more informed and making them more mediated.
    - Note: Why do journalism companies have an economic incentive to make consumers informed, more so than social media platforms? I am thinking about the article “Where Does The News Come From” and Toby Shorin’s “The Diminishing Value of Marginal Aesthetics”. Journalism is a particular slice of media, and media’s objective is to capture attention. Journalism may provide a public good, but it still has to capture attention. The attention it captures comes from people who want to be informed. Social media platforms also intend to inform people. I don’t think the execs at Instagram and TikTok would describe their products as being entertainment platforms. I think they would describe them as information platforms. So it would stand to reason that social media companies _do_ have an economic incentive to distinguish AI content from not. 
      It would also be right to point here that disinformation and misinformation go far beyond AI. Social media companies would have to discern all disinformation. 
      I guess this line of inquiry relies on the companies to maintain separate concepts of information and entertainment. Shorin’s point seems relevant here that aggregator social media platforms present information next to entertainment, so the frame surrounding each destabilizes. Here too there is a larger context. Social media is not the primary’s site where information and entertainment have blurred. That is a much larger problem. News does it. College does it!
      I mean don’t get me wrong, I understand the argument here. Social media relies on doom scrolling. But journalism has similar logic (see: 24-hour news cycle) and they are both media. Why do legitimize the social media platforms’ lack of action by adopting the position of economic growth?
- And the reason it's not good is because AI is trying to be photography and it is nothing like photography. The reason that photography is interesting to us is because of the way that it's created. It's because of how it's built, and it's because it's based in the real. And when you take that out, that image is boring. So what's happening is AI is like, oh, we can be the new photography, right? We can look so real, just like photography looks so, so real. But if it's not based in the real, those images hold very little interest to us.
    - Note: I think this point is interesting and I largely agree. But it seems important to note that photography is decidedly _not_ real. The world does not look like what a photograph looks like. The camera has many deviations from human visions — not to mention all of the automatic image processing that modern cameras do, nor even what post-production may do. Despite that, people look at photos and see reality. They “do not” see these discrepancies. (Of course, they actually do see them. Ask anyone who has taken a picture of a sunset or the moon or who complains they look bad in pictures)
      My point is that there may be value in thinking of these developments as points on a larger progression
- They are not actually then looking for or responding to authenticity. They're sort of responding to this the way I, I think about the, like the, the art they sell in the mall, right? Like nobody is going up to look at that art so that they can have an emotional experience with it. There are consumers on a slightly different level. I think the conflation of those levels though, do create a social problem for us.
- I do question, however, the difference between experts using it or artists. I should even just say using the tool to bring to life the conversation they want to have with the culture. And a AI prompt that someone comes up with off the cuff to send each other, you know, a funny video of them dancing in a Santa costume. I don't think that there are that many incentives for us to make that distinction online as part of the problem. And I'm not sure that we have the shared sensibilities to care that there's just so much more of the AI slop than there is the sort of, you know, artistic interpretation of AI.
- It isn't that there are billions of people programming and going and putting in one prompt at a time. It is that you can create an AI that will create a prompt based on generative AI text. The steps of human removal from the process isn't just human to prompt. Right. And if it was, then maybe, I don't know. Yeah, maybe we'd just be talking about the new era, you know, of pop art. It is that there is a point at which the human is. Can absolutely be removed from the loop entirely. And I think that that is one why it is so valuable to social media platforms who have figured out an equation where it is just about generating something new for people to respond to, whether they are actually having a strong emotional response or not.
    - Note: Well said
- But what we think of when we think of AI generated imagery is actually something that's like really slick and perfect and is sort of also akin to Trump's tackiness.
    - Note: Yes. This is why I have said that some concerns about AI taking away artist jobs are overblown. It will look tacky to use AI imagery in a campaign for your company. People don’t want their brands to be seen as tacky.
- Well, I think it's changing. The aesthetic that you just described is a very slick kind of plastic feeling to skin that we get.
    - Note: Also yes. Nano Banana is so good at looking like “regular” images
- I think if we over rely on aesthetics to tell us when AI has created an image or a video, then we have already fallen for the trick of AI which is to think that we individually alone can discern when it is enacted and when it isn't. I'm struck by how much of AI Slop is just sort of nihilistic in its position on society, that there's no choice about any of it. There's no political statement, there's no cultural statement, there's no artistic statement, except I made you respond. I captured your energy for about 8 seconds.
- I think that the reason you know that there's not sharks swimming in the flood outside your door is because it's not in the papers of the New York Times.
    - Note: Oh my, this is so grim and so not reflexive. Think through the implications of this. The NYT does not cover everything. Should walk outside my door and understand my surroundings as unreal until the NYT verifies it?
- Maybe we just had a little blip of enjoyment online for eight seconds and it's okay to let that just wash over us because ultimately that's all AI Slop is designed to do. It's just supposed to wash over us.
